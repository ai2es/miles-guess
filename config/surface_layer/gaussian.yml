callbacks:
  CSVLogger:
    append: false
    filename: training_log.csv
    separator: ','
  EarlyStopping:
    mode: min
    monitor: val_mae
    patience: 5
    verbose: 0
  ModelCheckpoint:
    filepath: model.h5
    mode: min
    monitor: val_mae
    save_best_only: true
    save_weights: true
    verbose: 0
  ReduceLROnPlateau:
    factor: 0.1
    min_delta: 1.0e-08
    min_lr: 1.0e-12
    mode: min
    monitor: val_mae
    patience: 2
    verbose: 0
data:
  input_cols:
  - wind_speed:10_m:m_s-1
  - potential_temperature_skin_change:10_m:K_m-1
  - bulk_richardson:10_m:None
  - mixing_ratio_skin_change:2_m:g_kg-1_m-1
  output_cols:
  - friction_velocity:surface:m_s-1
  save_loc: /glade/p/cisl/aiml/ai2es/surfacelayer/cabauw_derived_data_20210720.csv
  scaler_x:
    params:
      copy: true
      with_mean: true
      with_std: true
    type: quantile
  scaler_y:
    params:
      copy: true
      with_mean: true
      with_std: true
    type: normalize
  split_col: day
  splitter: GroupShuffleSplit
  train_size: 0.9
direction: max
ensemble:
  monte_carlo_passes: 100
  n_models: 1
  n_splits: 2
model:
  activation: relu
  batch_size: 3313
  dropout_alpha: 0.691716254026819
  epochs: 1000
  hidden_layers: 2
  hidden_neurons: 342
  kernel_reg: l2
  l1_weight: 0.0
  l2_weight: 2.2296992549467237e-10
  lr: 0.002351568426350059
  metrics: mae
  model_name: best.h5
  optimizer: adam
  save_path: ./
  use_dropout: true
  use_noise: false
  verbose: 2
pbs:
  account: NAML0001
  env_setup: "source ~/.bashrc \nmodule unload cuda cudnn \nconda activate /glade/work/schreck/miniconda3/envs/evidential\n\
    CUDNN_PATH=$(dirname $(python -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\"\
    ))\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/:$CUDNN_PATH/lib\n\
    export XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX"
  gpu_type: v100
  mem: 128GB
  name: g-fv-data
  ncpus: 8
  ngpus: 1
  queue: casper
  select: 1
  walltime: 86400
save_loc: ./
seed: 1000
training_metric: val_pitd
